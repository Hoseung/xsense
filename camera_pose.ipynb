{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average_frame.png의 카메라 위치와 hs_를 찍은 카메라 위치는 동일. \n",
    "\n",
    "이미지가 뒤집혀져있어서 ArUCo의 tvec, rvec을 뒤집어줘야함.  \n",
    "Camera matrix는 방향과 상관 없어서 뒤집지 않아도 됨. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    Compute the general 3D rotation matrix for rotations around the X, Y, and Z axes.\n",
    "\n",
    "    :param alpha: Rotation around the X-axis in radians\n",
    "    :param beta: Rotation around the Y-axis in radians\n",
    "    :param gamma: Rotation around the Z-axis in radians\n",
    "    :return: The combined 3D rotation matrix\n",
    "    \"\"\"\n",
    "    alpha = np.deg2rad(alpha)\n",
    "    beta = np.deg2rad(beta)\n",
    "    gamma = np.deg2rad(gamma)\n",
    "    # Rotation matrix for rotation around the X-axis\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(alpha), -np.sin(alpha)],\n",
    "                    [0, np.sin(alpha), np.cos(alpha)]])\n",
    "\n",
    "    # Rotation matrix for rotation around the Y-axis\n",
    "    R_y = np.array([[np.cos(beta), 0, np.sin(beta)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(beta), 0, np.cos(beta)]])\n",
    "\n",
    "    # Rotation matrix for rotation around the Z-axis\n",
    "    R_z = np.array([[np.cos(gamma), -np.sin(gamma), 0],\n",
    "                    [np.sin(gamma), np.cos(gamma), 0],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "    # Combine the rotations (Z * Y * X)\n",
    "    R = np.dot(R_z, np.dot(R_y, R_x))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = [(0,1),(1,2),(2,3), (3,4),(4,5),(5,6),\n",
    "               (4,7),(7,8),(8,9),(9,10),\n",
    "               (4,11), (11,12), (12,13), (13,14),\n",
    "               (0, 15), (15,16), (16,17), (17,18),\n",
    "               (0,19), (19,20), (20,21), (21,22)]\n",
    "\n",
    "connections_coco3d =[(0,1), (1,2), (0,3), (3,4),\n",
    "                    (1,9), (9,10), (10,11), \n",
    "                    (3,6), (6,7), (7,8),\n",
    "                    (9,5), (5,6)]\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080\n",
    "# Camera intrinsic parameters\n",
    "# 카메라 매트릭스와 왜곡 계수 (미리 구해둬야 함)\n",
    "CAMERA_MATRIX_ORG = np.array([[781.42789058, 0., 994.45013811],\n",
    "                          [0., 778.74286573, 602.69690385],\n",
    "                          [0., 0., 1.]])\n",
    "CAMERA_MATRIX = CAMERA_MATRIX_ORG.copy()\n",
    "CAMERA_MATRIX[0, 2] = image_width - CAMERA_MATRIX_ORG[0,2] # flip x\n",
    "CAMERA_MATRIX[1, 2] = image_height - CAMERA_MATRIX_ORG[1,2] # flip y\n",
    "DIST_COEFFS = np.array([[1.87498264e+01, 6.82542530e+00, -1.08541825e-04,\n",
    "                         -1.58742050e-05, 1.49993131e-01, 1.91587107e+01,\n",
    "                         1.32224486e+01, 1.15118961e+00, 0., 0., 0., 0.,\n",
    "                         0., 0.]])\n",
    "MARKER_LENGTH = 185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = json.load(open('./calibration/pose_data.json', \"r\"))\n",
    "rvec = np.array(pos['rvecs'])\n",
    "tvec = np.array(pos['tvecs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertcal_flip_rvec_tvec(rvec, tvec):\n",
    "    R_marker_to_camera, _ = cv2.Rodrigues(rvec)\n",
    "    # Flip matrix for upside-down correction (rotation of 180 degrees around the X-axis)\n",
    "    R_flip = np.array([[-1, 0, 0],\n",
    "                       [0, -1, 0],\n",
    "                       [0, 0, 1]])\n",
    "\n",
    "    # Apply the flip to the original rotation matrix\n",
    "    R_corrected = np.dot(R_flip, R_marker_to_camera)\n",
    "    tvec_corrected = np.dot(R_flip, tvec)\n",
    "\n",
    "    # Convert the corrected rotation matrix back to a rotation vector\n",
    "    rvec_corrected, _ = cv2.Rodrigues(R_corrected)\n",
    "    return rvec_corrected, tvec_corrected\n",
    "\n",
    "def draw_pos3d_cv(draw_image, imgpts, filename, connections=None):\n",
    "    for i, pts in enumerate(imgpts):\n",
    "        cv2.circle(draw_image, pts, 10, (0, 255, 0), -1)\n",
    "        cv2.putText(draw_image, f\"{i}\", pts, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "    for conn in connections_coco3d:\n",
    "        cv2.line(draw_image, [imgpts[conn[0],0], imgpts[conn[0],1]], \n",
    "                [imgpts[conn[1],0], imgpts[conn[1],1]], (255,0,0), 3)\n",
    "    cv2.imwrite(filename, draw_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image and draw the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration.utils import draw_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rvec [-0.16519393 -2.60398705 -1.45896214]\n",
      "Tvec [ 658.14184491 -573.62625472 1590.85946295]\n",
      "Rvec [[ 2.11282809]\n",
      " [-0.13403537]\n",
      " [ 0.18491364]]\n",
      "Tvec [-658.14184491  573.62625472 1590.85946295]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./imgs/hs_0001/1727861067542961.png')\n",
    "img = cv2.flip(img,0)\n",
    "img = cv2.flip(img,1)\n",
    "rvec = np.array(pos['rvecs'])\n",
    "tvec = np.array(pos['tvecs'])\n",
    "print(\"Rvec\", rvec)\n",
    "print(\"Tvec\", tvec)\n",
    "rvec, tvec = vertcal_flip_rvec_tvec(rvec, tvec)\n",
    "print(\"Rvec\", rvec)\n",
    "print(\"Tvec\", tvec)\n",
    "draw_image = draw_axis(img, rvec, tvec, CAMERA_MATRIX, DIST_COEFFS, MARKER_LENGTH)\n",
    "cv2.imwrite('tmp_hs.png', draw_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회전 변환 확인 됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Xsense to Camera Image plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Xsense to Camera Image plane\n",
    "\n",
    "마커:  \n",
    "+x: 화면 오른쪽  \n",
    "+y: 화면 안 쪽  \n",
    "+z: 위쪽   \n",
    "\n",
    "xsense: \n",
    "+x: 화면 바깥쪽 (= -y)  \n",
    "+y: 화면 오른쪽 (= +x)  \n",
    "+z: 위쪽 (= z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_pelvis(data):\n",
    "    # 골반 넓히기\n",
    "    l_vec = data[:,0] - data[:,15]\n",
    "    r_vec = data[:,0] - data[:,19]\n",
    "    data[:,15] = data[:,0] - 1.5*l_vec\n",
    "    data[:,19] = data[:,0] - 1.5*r_vec\n",
    "    \n",
    "    # 엉덩이 내리기\n",
    "    # h_vec = 0.5*(data[:,1] - data[:,0])\n",
    "    # data[:,0] -= h_vec\n",
    "    # data[:,15] -= h_vec\n",
    "    # data[:,19] -= h_vec\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"youngjin.npy\")\n",
    "data = data[3:]\n",
    "tmp = data[:,:,0].copy()\n",
    "data[:,:,0] = data[:,:,1]\n",
    "data[:,:,1] = -tmp\n",
    "\n",
    "data = enlarge_pelvis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO와 비슷한 모양으로 \n",
    "\n",
    "coco = np.zeros((len(data), 12, 3))\n",
    "coco[:,0] = data[:,0]\n",
    "coco[:,1] = data[:,19] # l hip\n",
    "coco[:,3] = data[:,15] # r hip\n",
    "coco[:,2] = data[:,20] # l knee\n",
    "coco[:,4] = data[:,16] # r knee\n",
    "coco[:,5] = data[:,6] # head\n",
    "coco[:,6] = data[:,8] # r shoulder\n",
    "coco[:,7] = data[:,9] # r elbow\n",
    "coco[:,8] = data[:,10] # r wrist\n",
    "coco[:,9] = data[:,12] # l shoulder\n",
    "coco[:,10] = data[:,13] # l elbow\n",
    "coco[:,11] = data[:,14] # l wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rot = rotation_matrix(-0, 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvec = np.array(pos['rvecs'])\n",
    "tvec = np.array(pos['tvecs'])\n",
    "rvec, tvec = vertcal_flip_rvec_tvec(rvec, tvec)\n",
    "\n",
    "zero_rotation = np.zeros((3, 1))\n",
    "zero_translation = np.zeros((3, 1))\n",
    "R_marker_to_camera, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "fixed_3d = np.zeros((len(coco), 12, 3))\n",
    "fixed_25d = np.zeros((len(coco), 12, 3))\n",
    "\n",
    "for ind in range(len(coco)):\n",
    "# for ind in [200, 10000,  20000]:\n",
    "    P_marker = coco[ind].copy() # np.array([1000,0,0])#data[0][:] # 골반 in marker's coordinate system\n",
    "    # P_marker *= 1.05\n",
    "    P_marker[:,0] -= 200\n",
    "    P_marker[:,1] -= 200\n",
    "    P_marker[:,2] += 10\n",
    "    P_marker = np.dot(Rot, P_marker.T).T\n",
    "    P_camera = np.dot(R_marker_to_camera, P_marker.T).T + tvec.T\n",
    "    fixed_3d[ind] = P_camera\n",
    "    \n",
    "    imgpts, _ = cv2.projectPoints(P_camera, zero_rotation, zero_translation, CAMERA_MATRIX, DIST_COEFFS)\n",
    "    imgpts = np.int32(imgpts).reshape(-1, 2)\n",
    "    fixed_25d[ind,:,:2] = imgpts\n",
    "    fixed_25d[ind,:,2] = P_camera[:,2]\n",
    "\n",
    "    if ind % 100 == 0:\n",
    "        #draw_pos3d(P_camera, f\"mw_{ind}_3D.png\", connections=connections_coco3d)\n",
    "        img = np.zeros((image_height, image_width, 3), np.uint8)\n",
    "        draw_pos3d_cv(img, imgpts, f\"./cv_yj/cv_yj_{ind}_3D.png\", connections=connections_coco3d)\n",
    "        \n",
    "    # img = cv2.imread('./imgs/Jemu_0004/1727870427366198.png')\n",
    "    # img = cv2.flip(img,0)\n",
    "    # img = cv2.flip(img,1)\n",
    "    # draw_pos3d_cv(img, imgpts, f\"test_{ind}_3D.png\", connections=connections_coco3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"youngjin_3d.npy\", fixed_3d)\n",
    "np.save(\"youngjin_25d.npy\", fixed_25d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pos3d(data, fn, connections=connections):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    x = data[:, 0]\n",
    "    y = data[:, 1]\n",
    "    z = data[:, 2]\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        ax.scatter(x[i], y[i], z[i], c='b', marker='o')\n",
    "        ax.text(x[i], y[i], z[i], f'{i}', color='black')\n",
    "\n",
    "    for conn in connections:\n",
    "        ax.plot([x[conn[0]], x[conn[1]]], [y[conn[0]], y[conn[1]]], [z[conn[0]], z[conn[1]]], c='b')\n",
    "\n",
    "    ax.set_xlim([-200, 1000])\n",
    "    ax.set_ylim([-1000, 1000])\n",
    "    ax.set_zlim([-50, 2000])\n",
    "\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    #ax.set_title(f\"Frame {frame_idx}\")\n",
    "    #plt.show()\n",
    "    plt.savefig(fn)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 좌표에서 골반 너비 조정. \n",
    "\n",
    "다른 키포인트도 COCO랑 동일한지 확인 필요\n",
    "\n",
    "확인용 그림 그려놓고, 바로바로 수정할 수 있도록\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
